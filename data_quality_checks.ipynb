{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMSHbBynWU3I7+zxgQe1Q5p",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/YagyanshB/nhs-data-science/blob/main/data_quality_checks.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tb8znK6ltn1f"
      },
      "outputs": [],
      "source": [
        "# data quality checks\n",
        "\n",
        "def run_nhs_data_quality_checks(filepath):\n",
        "    \"\"\"\n",
        "    Comprehensive data quality check for NHS patient data including demographics and clinical notes\n",
        "\n",
        "    Args:\n",
        "        filepath: Path to the combined NHS patient data with notes\n",
        "\n",
        "    Returns:\n",
        "        Dictionary with data quality metrics and summary\n",
        "    \"\"\"\n",
        "    print(f\"Running data quality checks on {filepath}\")\n",
        "\n",
        "    # Load data\n",
        "    try:\n",
        "        data = pd.read_csv(filepath)\n",
        "        print(f\"Successfully loaded dataset with {len(data)} records and {len(data.columns)} features\")\n",
        "    except Exception as e:\n",
        "        print(f\"Error loading data: {e}\")\n",
        "        return None\n",
        "\n",
        "    # Initialize results dictionary\n",
        "    quality_results = {\n",
        "        \"record_count\": len(data),\n",
        "        \"feature_count\": len(data.columns),\n",
        "        \"missing_data\": {},\n",
        "        \"outliers\": {},\n",
        "        \"consistency_issues\": [],\n",
        "        \"text_quality\": {}\n",
        "    }\n",
        "\n",
        "    # 1. Check for missing values\n",
        "    print(\"\\nChecking for missing values...\")\n",
        "    missing_counts = data.isnull().sum()\n",
        "    missing_percent = (missing_counts / len(data)) * 100\n",
        "\n",
        "    missing_summary = pd.DataFrame({\n",
        "        'missing_values': missing_counts,\n",
        "        'percent_missing': missing_percent\n",
        "    }).sort_values('percent_missing', ascending=False)\n",
        "\n",
        "    quality_results[\"missing_data\"][\"summary\"] = missing_summary[missing_summary['missing_values'] > 0].to_dict()\n",
        "    quality_results[\"missing_data\"][\"total_missing_percentage\"] = (data.isnull().sum().sum() / (data.shape[0] * data.shape[1])) * 100\n",
        "\n",
        "    # Print missing values summary\n",
        "    print(missing_summary[missing_summary['missing_values'] > 0])\n",
        "\n",
        "    # 2. Check for demographic data quality\n",
        "    print(\"\\nChecking demographic data quality...\")\n",
        "\n",
        "    # Age range check\n",
        "    age_min, age_max = data['age'].min(), data['age'].max()\n",
        "    invalid_ages = ((data['age'] < 18) | (data['age'] > 110)).sum()\n",
        "    quality_results[\"demographics\"] = {\n",
        "        \"age_range\": f\"{age_min} - {age_max}\",\n",
        "        \"invalid_ages\": invalid_ages\n",
        "    }\n",
        "    print(f\"Age range: {age_min} - {age_max}\")\n",
        "    print(f\"Invalid ages (< 18 or > 110): {invalid_ages}\")\n",
        "\n",
        "    # Gender distribution\n",
        "    gender_counts = data['gender'].value_counts()\n",
        "    quality_results[\"demographics\"][\"gender_distribution\"] = gender_counts.to_dict()\n",
        "    print(\"Gender distribution:\")\n",
        "    print(gender_counts)\n",
        "\n",
        "    # Ethnicity check\n",
        "    ethnicity_counts = data['ethnicity'].value_counts()\n",
        "    quality_results[\"demographics\"][\"ethnicity_distribution\"] = ethnicity_counts.to_dict()\n",
        "    print(\"\\nEthnicity distribution:\")\n",
        "    print(ethnicity_counts)\n",
        "\n",
        "    # IMD quintile check\n",
        "    imd_counts = data['imd_quintile'].value_counts().sort_index()\n",
        "    quality_results[\"demographics\"][\"imd_distribution\"] = imd_counts.to_dict()\n",
        "    print(\"\\nIMD quintile distribution:\")\n",
        "    print(imd_counts)\n",
        "\n",
        "    # Check for invalid IMD values\n",
        "    invalid_imd = ((data['imd_quintile'] < 1) | (data['imd_quintile'] > 5)).sum()\n",
        "    quality_results[\"demographics\"][\"invalid_imd\"] = invalid_imd\n",
        "    print(f\"Invalid IMD values (not 1-5): {invalid_imd}\")\n",
        "\n",
        "    # 3. Check clinical variables\n",
        "    print(\"\\nChecking clinical variables...\")\n",
        "\n",
        "    # NEWS2 score range check\n",
        "    news_min, news_max = data['news2_score'].min(), data['news2_score'].max()\n",
        "    invalid_news = ((data['news2_score'] < 0) | (data['news2_score'] > 20)).sum()\n",
        "    quality_results[\"clinical\"] = {\n",
        "        \"news2_range\": f\"{news_min} - {news_max}\",\n",
        "        \"invalid_news2\": invalid_news\n",
        "    }\n",
        "    print(f\"NEWS2 score range: {news_min} - {news_max}\")\n",
        "    print(f\"Invalid NEWS2 scores (< 0 or > 20): {invalid_news}\")\n",
        "\n",
        "    # Charlson index check\n",
        "    charlson_min, charlson_max = data['charlson_index'].min(), data['charlson_index'].max()\n",
        "    invalid_charlson = ((data['charlson_index'] < 0) | (data['charlson_index'] > 25)).sum()\n",
        "    quality_results[\"clinical\"][\"charlson_range\"] = f\"{charlson_min} - {charlson_max}\"\n",
        "    quality_results[\"clinical\"][\"invalid_charlson\"] = invalid_charlson\n",
        "    print(f\"Charlson index range: {charlson_min} - {charlson_max}\")\n",
        "    print(f\"Invalid Charlson values (< 0 or > 25): {invalid_charlson}\")\n",
        "\n",
        "    # Primary diagnosis check\n",
        "    diagnosis_counts = data['primary_diagnosis'].value_counts()\n",
        "    quality_results[\"clinical\"][\"diagnosis_distribution\"] = diagnosis_counts.to_dict()\n",
        "    print(\"\\nTop 5 primary diagnoses:\")\n",
        "    print(diagnosis_counts.head(5))\n",
        "\n",
        "    # 4. Check for logical consistency\n",
        "    print(\"\\nChecking for logical consistency...\")\n",
        "\n",
        "    # Check if high risk patients have reasonable risk factors\n",
        "    high_risk = data[data['readmission_risk'] > 0.7]\n",
        "    high_risk_without_factors = high_risk[\n",
        "        (high_risk['age'] < 65) &\n",
        "        (high_risk['charlson_index'] < 3) &\n",
        "        (high_risk['previous_admissions_12mo'] == 0) &\n",
        "        (~high_risk['primary_diagnosis'].isin(['Heart Failure', 'COPD', 'Frailty', 'Renal Failure']))\n",
        "    ]\n",
        "\n",
        "    consistency_issue = {\n",
        "        \"issue\": \"High risk patients without major risk factors\",\n",
        "        \"count\": len(high_risk_without_factors),\n",
        "        \"percentage\": (len(high_risk_without_factors) / len(high_risk)) * 100\n",
        "    }\n",
        "    quality_results[\"consistency_issues\"].append(consistency_issue)\n",
        "\n",
        "    print(f\"High risk patients without typical risk factors: {len(high_risk_without_factors)} \" +\n",
        "          f\"({(len(high_risk_without_factors) / len(high_risk)) * 100:.1f}% of high risk patients)\")\n",
        "\n",
        "    # 5. Clinical notes quality\n",
        "    print(\"\\nAnalyzing clinical notes quality...\")\n",
        "\n",
        "    # Note length check\n",
        "    if 'clinical_note' in data.columns:\n",
        "        data['note_length'] = data['clinical_note'].str.len()\n",
        "        note_min, note_mean, note_max = data['note_length'].min(), data['note_length'].mean(), data['note_length'].max()\n",
        "\n",
        "        quality_results[\"text_quality\"] = {\n",
        "            \"note_length_stats\": {\n",
        "                \"min\": note_min,\n",
        "                \"mean\": note_mean,\n",
        "                \"max\": note_max\n",
        "            }\n",
        "        }\n",
        "\n",
        "        # Check for suspiciously short notes\n",
        "        short_notes = (data['note_length'] < 50).sum()\n",
        "        quality_results[\"text_quality\"][\"short_notes_count\"] = short_notes\n",
        "        quality_results[\"text_quality\"][\"short_notes_percent\"] = (short_notes / len(data)) * 100\n",
        "\n",
        "        print(f\"Clinical note length - Min: {note_min}, Mean: {note_mean:.1f}, Max: {note_max}\")\n",
        "        print(f\"Suspiciously short notes (<50 chars): {short_notes} ({(short_notes/len(data))*100:.1f}%)\")\n",
        "\n",
        "        # Check if notes contain expected clinical terms\n",
        "        clinical_terms = ['patient', 'presented', 'symptoms', 'treatment', 'plan', 'prescribed', 'assessed']\n",
        "        term_presence = {}\n",
        "\n",
        "        for term in clinical_terms:\n",
        "            term_count = data['clinical_note'].str.contains(term, case=False).sum()\n",
        "            term_presence[term] = {\n",
        "                \"count\": term_count,\n",
        "                \"percentage\": (term_count / len(data)) * 100\n",
        "            }\n",
        "\n",
        "        quality_results[\"text_quality\"][\"clinical_terms_presence\"] = term_presence\n",
        "\n",
        "        print(\"\\nPresence of expected clinical terms:\")\n",
        "        for term, stats in term_presence.items():\n",
        "            print(f\"'{term}': {stats['count']} records ({stats['percentage']:.1f}%)\")\n",
        "\n",
        "    # 6. Visualize key quality metrics\n",
        "    print(\"\\nGenerating data quality visualizations...\")\n",
        "\n",
        "    # Missing data heatmap\n",
        "    plt.figure(figsize=(12, 8))\n",
        "    sns.heatmap(data.isnull(), yticklabels=False, cbar=False, cmap='viridis')\n",
        "    plt.title('Missing Value Heatmap')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('missing_data_heatmap.png')\n",
        "\n",
        "    # Readmission risk distribution\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    sns.histplot(data['readmission_risk'], bins=20, kde=True)\n",
        "    plt.title('Readmission Risk Distribution')\n",
        "    plt.xlabel('Readmission Risk')\n",
        "    plt.ylabel('Count')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('readmission_risk_distribution.png')\n",
        "\n",
        "\n",
        "    # Age vs Charlson Index scatter with readmission outcome\n",
        "    plt.figure(figsize=(10, 6))\n",
        "    # Sample at most the size of the dataset\n",
        "    sample_size = min(1000, len(data))\n",
        "    sns.scatterplot(x='age', y='charlson_index', hue='readmitted_within_30d', data=data.sample(sample_size))\n",
        "    plt.title('Age vs Charlson Index by Readmission Status')\n",
        "    plt.xlabel('Age')\n",
        "    plt.ylabel('Charlson Comorbidity Index')\n",
        "    plt.tight_layout()\n",
        "    plt.savefig('age_charlson_readmission.png')\n",
        "\n",
        "\n",
        "    # Note length distribution\n",
        "    if 'note_length' in data.columns:\n",
        "        plt.figure(figsize=(10, 6))\n",
        "        sns.histplot(data['note_length'], bins=30, kde=True)\n",
        "        plt.title('Clinical Note Length Distribution')\n",
        "        plt.xlabel('Number of Characters')\n",
        "        plt.ylabel('Count')\n",
        "        plt.tight_layout()\n",
        "        plt.savefig('note_length_distribution.png')\n",
        "\n",
        "    # Summary\n",
        "    print(\"\\nData Quality Summary:\")\n",
        "    print(f\"- Total records: {quality_results['record_count']}\")\n",
        "    print(f\"- Missing data: {quality_results['missing_data']['total_missing_percentage']:.2f}% overall\")\n",
        "    print(f\"- Demographics issues: {quality_results['demographics']['invalid_ages']} invalid ages, \" +\n",
        "          f\"{quality_results['demographics']['invalid_imd']} invalid IMD values\")\n",
        "    print(f\"- Clinical data issues: {quality_results['clinical']['invalid_news2']} invalid NEWS2 scores, \" +\n",
        "          f\"{quality_results['clinical']['invalid_charlson']} invalid Charlson indices\")\n",
        "    print(f\"- Logical consistency issues: {len(quality_results['consistency_issues'])} issues identified\")\n",
        "    if 'clinical_note' in data.columns:\n",
        "        print(f\"- Text quality: {quality_results['text_quality']['short_notes_count']} suspiciously short notes\")\n",
        "\n",
        "    return quality_results\n",
        "\n",
        "# Run the quality checks and print results\n",
        "if __name__ == \"__main__\":\n",
        "    quality_results = run_nhs_data_quality_checks('nhs_patient_data_with_notes.csv')\n",
        "    print(\"\\n✅ Data quality assessment complete\")"
      ]
    }
  ]
}